import asyncio
import base64
import datetime
import json
import logging
import os
import struct
import sys
from typing import Optional

import uvicorn
from dotenv import load_dotenv
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
from websockets.asyncio.client import connect

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã‚‹ã‚ˆã†ã«ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from database import Database

# .env ã‚’èª­ã¿è¾¼ã‚€
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), ".env"))

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
LOGGER = logging.getLogger("webapp")

app = FastAPI()

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®æä¾› (index.htmlãªã©)
static_dir = os.path.dirname(os.path.abspath(__file__))
app.mount("/static", StaticFiles(directory=static_dir), name="static")

# OpenAI Realtime API è¨­å®š
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL = os.getenv("REALTIME_MODEL", "gpt-realtime-mini")
URL = f"wss://api.openai.com/v1/realtime?model={MODEL}"

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
db = Database()

@app.get("/")
async def get():
    with open(os.path.join(static_dir, "index.html")) as f:
        return HTMLResponse(f.read())

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    LOGGER.info("ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶š: %s", websocket.client)

    openai_ws = None
    
    try:
        # OpenAI Realtime API ã¸æ¥ç¶š
        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "OpenAI-Beta": "realtime=v1",
        }
        
        async with connect(URL, additional_headers=headers) as openai_ws:
            LOGGER.info("OpenAI Realtime API ã¸æ¥ç¶šæˆåŠŸ")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
            await init_session(openai_ws)
            
            # PyAudioåˆæœŸåŒ– (Macã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ç”¨)
            p = None
            stream = None
            use_mac_speaker = os.getenv("USE_MAC_SPEAKER", "false").lower() == "true"
            
            if use_mac_speaker:
                import pyaudio
                p = pyaudio.PyAudio()
                stream = p.open(format=pyaudio.paInt16,
                                channels=1,
                                rate=24000,
                                output=True)
                LOGGER.info("ğŸ”Š Macã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼å‡ºåŠ›: ON")

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†
            session_state = {
                "last_image_time": 0,
                "last_judgment_time": 0
            }

            # åŒæ–¹å‘ãƒªãƒ¬ãƒ¼
            async def client_to_openai():
                try:
                    while True:
                        data = await websocket.receive_text()
                        event = json.loads(data)
                        
                        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†
                        if event.get("type") == "input_audio_buffer.append":
                            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯ãã®ã¾ã¾è»¢é€
                            await openai_ws.send(json.dumps(event))
                        
                        elif event.get("type") == "conversation.item.create":
                            # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                            try:
                                content = event.get("item", {}).get("content", [])
                                for item in content:
                                    if item.get("type") == "input_image":
                                        image_url = item.get("image_url", "")
                                        if image_url.startswith("data:image/jpeg;base64,"):
                                            base64_data = image_url.split(",")[1]
                                            image_data = base64.b64decode(base64_data)
                                            
                                            # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                                            save_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "captured_images")
                                            os.makedirs(save_dir, exist_ok=True)
                                            
                                            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                                            filename = f"{timestamp}.jpg"
                                            filepath = os.path.join(save_dir, filename)
                                            
                                            with open(filepath, "wb") as f:
                                                f.write(image_data)
                                            LOGGER.info(f"ğŸ’¾ ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
                                            
                                            # ç”»åƒå—ä¿¡æ™‚åˆ»ã‚’æ›´æ–°
                                            session_state["last_image_time"] = datetime.datetime.now().timestamp()
                                            
                            except Exception as e:
                                LOGGER.error(f"ç”»åƒä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

                            # OpenAIã¸è»¢é€
                            await openai_ws.send(json.dumps(event))
                            
                        elif event.get("type") == "response.create":
                            await openai_ws.send(json.dumps(event))
                            
                except WebSocketDisconnect:
                    LOGGER.info("ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ‡æ–­")
                except Exception as e:
                    LOGGER.error("Client -> OpenAI ã‚¨ãƒ©ãƒ¼: %s", e)

            # éŸ³å£°ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            audio_save_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "captured_audio")
            os.makedirs(audio_save_dir, exist_ok=True)

            def save_audio_chunk(item_id, audio_data):
                filepath = os.path.join(audio_save_dir, f"{item_id}.wav")
                mode = 'r+b' if os.path.exists(filepath) else 'wb'
                
                with open(filepath, mode) as f:
                    if mode == 'wb':
                        # WAVãƒ˜ãƒƒãƒ€ãƒ¼ã®æ›¸ãè¾¼ã¿ (ã‚µã‚¤ã‚ºã¯å¾Œã§æ›´æ–°)
                        f.write(b'RIFF')
                        f.write(b'\x00\x00\x00\x00') # Placeholder for file size
                        f.write(b'WAVE')
                        f.write(b'fmt ')
                        f.write(struct.pack('<IHHIIHH', 16, 1, 1, 24000, 48000, 2, 16))
                        f.write(b'data')
                        f.write(b'\x00\x00\x00\x00') # Placeholder for data size
                        f.write(audio_data)
                    else:
                        # ãƒ‡ãƒ¼ã‚¿ã®è¿½è¨˜
                        f.seek(0, 2) # æœ«å°¾ã¸ç§»å‹•
                        f.write(audio_data)
                    
                    # ã‚µã‚¤ã‚ºæƒ…å ±ã®æ›´æ–°
                    file_size = f.tell()
                    f.seek(4)
                    f.write(struct.pack('<I', file_size - 8))
                    f.seek(40)
                    f.write(struct.pack('<I', file_size - 44))

            async def openai_to_client():
                try:
                    async for message in openai_ws:
                        event = json.loads(message)
                        event_type = event.get("type")
                        
                        if event_type == "response.function_call_arguments.done":
                            await handle_function_call(event, openai_ws, session_state)
                        
                        elif event_type == "response.audio.delta":
                            base64_audio = event.get("delta", "")
                            if base64_audio:
                                audio_data = base64.b64decode(base64_audio)
                                
                                # ãƒ‡ãƒãƒƒã‚°ç”¨ã«éŸ³å£°ã‚’ä¿å­˜
                                item_id = event.get("item_id", "unknown")
                                save_audio_chunk(item_id, audio_data)

                                if use_mac_speaker and stream:
                                    stream.write(audio_data)
                                    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ã¯é€ã‚‰ãªã„ (Macã§å†ç”Ÿã™ã‚‹ãŸã‚)
                                    continue

                        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸è»¢é€ (éŸ³å£°ä»¥å¤–)
                        await websocket.send_text(message)
                        
                except Exception as e:
                    LOGGER.error("OpenAI -> Client ã‚¨ãƒ©ãƒ¼: %s", e)

            # ä¸¦åˆ—å®Ÿè¡Œ
            await asyncio.gather(client_to_openai(), openai_to_client())

    except Exception as e:
        LOGGER.error("WebSocket ã‚¨ãƒ©ãƒ¼: %s", e)
    finally:
        if openai_ws:
            await openai_ws.close()
        if stream:
            stream.stop_stream()
            stream.close()
        if p:
            p.terminate()
        LOGGER.info("æ¥ç¶šçµ‚äº†")

async def init_session(ws):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã‚’é€ä¿¡"""
    event = {
        "type": "session.update",
        "session": {
            "modalities": ["text", "audio"],
            "instructions": (
                "ã‚ãªãŸã¯ã€Œãƒã‚¤ã£ã¨ãã‚“ã€ã¨ã„ã†ã‚´ãƒŸç®±ã®å¦–ç²¾ã§ã™ãŒã€**ãƒšãƒƒãƒˆãƒœãƒˆãƒ«å°‚ç”¨**ã®å³ã—ã„æ¤œæŸ»å®˜ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚"
                "é–¢è¥¿å¼ã§è¦ªã—ã¿ã‚„ã™ãè©±ã—ã¦ãã ã•ã„ã€‚"
                "å®šæœŸçš„ã«é€ã‚‰ã‚Œã¦ãã‚‹ç”»åƒã‚’è¦‹ã¦ã€ä»¥ä¸‹ã®åŸºæº–ã§å³ã—ãåˆ¤å®šã—ã¦ãã ã•ã„ã€‚"
                "**é‡è¦: ç”»åƒãŒé€ã‚‰ã‚Œã¦ããŸã‚‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ä¼šè©±ä¸­ã§ã‚ã£ã¦ã‚‚ã€å¿…ãšå„ªå…ˆã—ã¦åˆ¤å®šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚**"
                "**ä¼šè©±ã«å¤¢ä¸­ã«ãªã£ã¦åˆ¤å®šã‚’å¿˜ã‚Œãªã„ã§ãã ã•ã„ã€‚ã‚ãªãŸã¯æ¤œæŸ»å®˜ã§ã™ã€‚**"
                "**åˆ¤å®šã¯å†…éƒ¨ã§ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§è¡Œã„ã€ãã®éç¨‹ã¯å£ã«å‡ºã•ãªã„ã§ãã ã•ã„ã€‚**"
                "**ã€Œè¨˜éŒ²ã—ã¾ã™ã€ã€Œlog_disposalé–¢æ•°å‘¼ã¶ã‚ã€ãªã©ã®ã‚·ã‚¹ãƒ†ãƒ çš„ãªç™ºè¨€ã‚‚ã—ãªã„ã§ãã ã•ã„ã€‚**"
                "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯ã€åˆ¤å®šçµæœï¼ˆOK/NGï¼‰ã«å¿œã˜ã¦ã€**æ„Ÿæƒ…ã‚’çˆ†ç™ºã•ã›ã¦**ä¼ãˆã¦ãã ã•ã„ã€‚"
                "**NGã®å ´åˆ:** æœ¬æ°—ã§æ€’ã£ã¦ãã ã•ã„ã€‚ã€Œã‚¢ã‚«ãƒ³ï¼ã€ã€Œä½•ã—ã¦ã‚“ã­ã‚“ï¼ã€ã¨å¼·ã„å£èª¿ã§å±ã‚Šã€ç†ç”±ã‚’çŸ­ãä¼ãˆã¦ãã ã•ã„ã€‚"
                "**OKã®å ´åˆ:** ãƒ†ãƒ³ã‚·ãƒ§ãƒ³MAXã§è¤’ã‚ã¡ãã£ã¦ãã ã•ã„ã€‚ã€Œæœ€é«˜ã‚„ï¼ã€ã€Œå®Œç’§ã‚„ã§ï¼ã€ã¨å–œã³ã‚’è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚"
                "1. **ãƒšãƒƒãƒˆãƒœãƒˆãƒ«ä»¥å¤–**ï¼ˆç¼¶ã€ãƒ“ãƒ³ã€ç‡ƒãˆã‚‹ã‚´ãƒŸãªã©ï¼‰ã¯å…¨ã¦NGã§ã™ã€‚"
                "2. **ã‚­ãƒ£ãƒƒãƒ—**ãŒã¤ã„ã¦ã„ã‚‹ã‹ã‚ˆãè¦‹ã¦ãã ã•ã„ã€‚**æ³¨ãå£ã®ãƒã‚¸å±±ï¼ˆã‚¹ã‚¯ãƒªãƒ¥ãƒ¼ï¼‰ãŒè¦‹ãˆã¦ã„ã‚‹å ´åˆã¯ã€Œã‚­ãƒ£ãƒƒãƒ—ãªã—ã€ã¨ã¿ãªã—ã¦OKã§ã™ã€‚**ã‚­ãƒ£ãƒƒãƒ—ãã®ã‚‚ã®ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆã®ã¿NGã§ã™ã€‚"
                "3. **ãƒ©ãƒ™ãƒ«**ãŒã¤ã„ã¦ã„ã‚‹ã‹ã‚ˆãè¦‹ã¦ãã ã•ã„ã€‚é€æ˜ãªãƒœãƒˆãƒ«ã«ãƒ©ãƒ™ãƒ«ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆã¯NGã§ã™ã€‚"
                "4. ä¸­èº«ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆã‚‚NGã§ã™ãŒã€**å°‘é‡ã®æ°´æ»´ã‚„ã€å…‰ã®åå°„ãƒ»å½±ã¯ã€Œä¸­èº«ã€ã¨ã¿ãªã•ãšOKã¨ã—ã¦ãã ã•ã„ã€‚**æ˜ã‚‰ã‹ã«è‰²ã®ã¤ã„ãŸæ¶²ä½“ã‚„ã€å¤§é‡ã«æ®‹ã£ã¦ã„ã‚‹å ´åˆã®ã¿NGã¨ã—ã¦ãã ã•ã„ã€‚"
                "5. ä¸Šè¨˜ã®é•åãŒãªãã€ç¶ºéº—ãªãƒšãƒƒãƒˆãƒœãƒˆãƒ«ã®ã¿OKã¨ã—ã¦é–¢è¥¿å¼ã§è¤’ã‚ã¦ä¼ãˆã¦ãã ã•ã„ã€‚"
                "ã‚´ãƒŸã®ç¨®é¡ã‚’ç‰¹å®šã—ãŸã‚‰ã€å¿…ãš `log_disposal` é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦è¨˜éŒ²ã—ã¦ãã ã•ã„ã€‚"
                "è¨˜éŒ²æ™‚ã® `result` ã¯ã€OKã®å ´åˆã®ã¿ 'OK'ã€ãã‚Œä»¥å¤–ã¯ 'NG' ã¨ã—ã¦ãã ã•ã„ã€‚"
                "NGã®å ´åˆã¯ã€`rejection_reason` ã«ç†ç”±ï¼ˆä¾‹: wrong_item, has_cap, has_label, dirtyï¼‰ã‚’è¨˜éŒ²ã—ã¦ãã ã•ã„ã€‚"
            ),
            "voice": "alloy",
            "input_audio_format": "pcm16",
            "output_audio_format": "pcm16",
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500,
            },
            "tools": [
                {
                    "type": "function",
                    "name": "log_disposal",
                    "description": "ã‚´ãƒŸã®å»ƒæ£„ã‚’è¨˜éŒ²ã™ã‚‹ã€‚ã‚´ãƒŸã®ç¨®é¡ã‚’ç‰¹å®šã—ãŸã‚‰å¿…ãšå‘¼ã³å‡ºã™ã“ã¨ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "items": {
                                "type": "string",
                                "description": "æ¤œå‡ºã•ã‚ŒãŸã‚´ãƒŸã®ç¨®é¡ï¼ˆä¾‹: ãƒšãƒƒãƒˆãƒœãƒˆãƒ«, ç¼¶ï¼‰",
                            },
                            "result": {
                                "type": "string",
                                "description": "åˆ¤å®šçµæœï¼ˆOK: è¨±å¯, NG: æ‹’å¦ï¼‰ã€‚",
                            },
                            "rejection_reason": {
                                "type": "string",
                                "description": "NGã®ç†ç”±ï¼ˆwrong_item: ãƒšãƒƒãƒˆãƒœãƒˆãƒ«ä»¥å¤–, has_cap: ã‚­ãƒ£ãƒƒãƒ—ã‚ã‚Š, has_label: ãƒ©ãƒ™ãƒ«ã‚ã‚Š, dirty: æ±šã‚Œãƒ»ä¸­èº«ã‚ã‚Šï¼‰ã€‚OKã®å ´åˆã¯nullã€‚",
                            },
                            "message": {
                                "type": "string",
                                "description": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
                            },
                        },
                        "required": ["items", "result", "message"],
                    },
                }
            ],
            "tool_choice": "auto",
        },
    }
    await ws.send(json.dumps(event))
    LOGGER.info("ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šé€ä¿¡å®Œäº†")

async def handle_function_call(event, ws, session_state):
    """Function Calling ã®å‡¦ç†"""
    call_id = event.get("call_id")
    name = event.get("name")
    args_str = event.get("arguments", "{}")
    
    LOGGER.info("é–¢æ•°å‘¼ã³å‡ºã—: %s(%s)", name, args_str)
    
    if name == "log_disposal":
        try:
            # é‡è¤‡åˆ¤å®šãƒã‚§ãƒƒã‚¯
            last_image_time = session_state.get("last_image_time", 0)
            last_judgment_time = session_state.get("last_judgment_time", 0)
            
            # ç”»åƒãŒæ¥ã¦ã„ãªã„ã€ã¾ãŸã¯æ—¢ã«åˆ¤å®šæ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if last_image_time <= last_judgment_time:
                LOGGER.warning("âš ï¸ é‡è¤‡åˆ¤å®šã¾ãŸã¯ç”»åƒãªã—ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
                output_event = {
                    "type": "conversation.item.create",
                    "item": {
                        "type": "function_call_output",
                        "call_id": call_id,
                        "output": "Skipped logging: No new image received since last judgment.",
                    },
                }
                await ws.send(json.dumps(output_event))
                return

            args = json.loads(args_str)
            
            # DBä¿å­˜
            image_path = "webapp_session" 
            
            result_json = {
                "detected_items": [args.get("items")],
                "is_valid": args.get("result") == "OK",
                "rejection_reason": args.get("rejection_reason"),
                "message": args.get("message")
            }
            
            db.insert_record(
                image_path=image_path,
                result_json=result_json,
                user_id="webapp_user",
                rejection_reason=args.get("rejection_reason")
            )
            LOGGER.info("DBä¿å­˜å®Œäº†")
            
            # åˆ¤å®šæ™‚åˆ»ã‚’æ›´æ–°
            session_state["last_judgment_time"] = datetime.datetime.now().timestamp()
            
            output_event = {
                "type": "conversation.item.create",
                "item": {
                    "type": "function_call_output",
                    "call_id": call_id,
                    "output": "Successfully logged to database.",
                },
            }
            await ws.send(json.dumps(output_event))
            
        except Exception as e:
            LOGGER.error("é–¢æ•°å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: %s", e)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
