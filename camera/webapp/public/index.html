<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>ãƒã‚¤ã£ã¨ãã‚“ WebApp</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            background-color: #000;
            color: #fff;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            height: 100vh;
            overflow: hidden;
        }

        #controls {
            padding: 20px;
            padding-top: env(safe-area-inset-top, 20px);
            /* iPhoneã®ãƒãƒƒãƒå¯¾ç­– */
            background: rgba(0, 0, 0, 0.8);
            display: flex;
            flex-direction: column;
            gap: 15px;
            border-bottom-left-radius: 20px;
            border-bottom-right-radius: 20px;
            z-index: 10;
            /* ãƒ“ãƒ‡ã‚ªã®ä¸Šã«è¡¨ç¤º */
        }

        #video-container {
            flex: 1;
            position: relative;
            background: #000;
            display: flex;
            justify-content: center;
            align-items: center;
            margin-top: -20px;
            /* è§’ä¸¸ã®éš™é–“ã‚’åŸ‹ã‚ã‚‹ */
        }

        video {
            width: 100%;
            height: 100%;
            object-fit: contain;
            /* å…¨ä½“ã‚’è¡¨ç¤ºï¼ˆã‚¯ãƒ­ãƒƒãƒ—ã—ãªã„ï¼‰ */
        }

        .row {
            display: flex;
            justify-content: space-between;
            gap: 10px;
        }

        button {
            flex: 1;
            padding: 15px;
            border: none;
            border-radius: 12px;
            background: #333;
            color: #fff;
            font-size: 16px;
            font-weight: bold;
            cursor: pointer;
            transition: background 0.2s;
            -webkit-tap-highlight-color: transparent;
        }

        button:active {
            background: #555;
        }

        button.active {
            background: #FFCC00;
            /* ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ONæ™‚ã¯é»„è‰² */
            color: #000;
        }

        button.recording {
            background: #FF3B30;
        }

        select {
            flex: 1;
            padding: 10px;
            border-radius: 8px;
            font-size: 16px;
            background: #333;
            color: white;
            border: 1px solid #555;
        }

        #status {
            text-align: center;
            font-size: 14px;
            color: #888;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        /* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ */
        .status-indicator {
            display: inline-block;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            margin-right: 8px;
        }

        .status-indicator.connected {
            background: #4CD964;
        }

        .status-indicator.disconnected {
            background: #FF3B30;
        }

        .status-indicator.connecting {
            background: #FFCC00;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        /* ãƒˆãƒ¼ã‚¹ãƒˆé€šçŸ¥ */
        .toast {
            position: fixed;
            bottom: 100px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0, 0, 0, 0.8);
            color: #fff;
            padding: 12px 24px;
            border-radius: 8px;
            opacity: 0;
            transition: opacity 0.3s;
            z-index: 1000;
            max-width: 80%;
            text-align: center;
        }

        .toast.show {
            opacity: 1;
        }

        .toast.error {
            background: rgba(255, 59, 48, 0.9);
        }

        .toast.success {
            background: rgba(76, 217, 100, 0.9);
        }
    </style>
</head>

<body>
    <div id="toast" class="toast"></div>
    <div id="controls">
        <div id="status"><span class="status-indicator disconnected"></span>æœªæ¥ç¶š</div>

        <div class="row">
            <select id="camera-select">
                <option value="">ã‚«ãƒ¡ãƒ©ã‚’é¸æŠ...</option>
            </select>
        </div>

        <div class="row">
            <button id="connect-btn">æ¥ç¶šé–‹å§‹</button>
            <button id="detect-btn" disabled>ã‚´ãƒŸæ¤œçŸ¥é–‹å§‹</button>
        </div>
        <div class="row">
            <button id="flash-btn" disabled>âš¡ Flash</button>
        </div>
    </div>

    <div id="video-container">
        <video id="video" autoplay playsinline muted></video>
    </div>

    <script>
        const video = document.getElementById('video');
        const cameraSelect = document.getElementById('camera-select');
        const connectBtn = document.getElementById('connect-btn');
        const detectBtn = document.getElementById('detect-btn');
        const flashBtn = document.getElementById('flash-btn');
        const statusDiv = document.getElementById('status');

        let stream = null;
        let ws = null;
        let audioContext = null;
        let audioWorkletNode = null;
        let track = null; // Video track for flash control
        let imageInterval = null; // Interval ID for image loop
        let wsToken = null; // WebSocketèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³

        // ã‚«ãƒ¡ãƒ©ãƒ©ãƒ™ãƒ«ã‚’æ—¥æœ¬èªåŒ–
        function formatCameraLabel(label) {
            if (!label) return null;
            const lower = label.toLowerCase();

            // iOS æ—¥æœ¬èªãƒ©ãƒ™ãƒ«å¯¾å¿œ
            if (label.includes('èƒŒé¢è¶…åºƒè§’')) return 'ğŸ” è¶…åºƒè§’ (0.5x)';
            if (label.includes('èƒŒé¢ãƒ‡ãƒ¥ã‚¢ãƒ«åºƒè§’')) return 'ğŸ“· èƒŒé¢åºƒè§’';
            if (label.includes('èƒŒé¢ã‚«ãƒ¡ãƒ©')) return 'ğŸ“· èƒŒé¢';
            if (label.includes('å‰é¢ã‚«ãƒ¡ãƒ©')) return 'ğŸ¤³ å‰é¢';
            if (label.includes('å‰é¢')) return 'ğŸ¤³ å‰é¢';
            if (label.includes('èƒŒé¢')) return 'ğŸ“· èƒŒé¢åºƒè§’';

            // è‹±èªãƒ©ãƒ™ãƒ«å¯¾å¿œ
            if (lower.includes('ultra wide') || lower.includes('0.5')) return 'ğŸ” è¶…åºƒè§’ (0.5x)';
            if (lower.includes('telephoto')) return 'ğŸ”­ æœ›é ';
            if (lower.includes('front')) return 'ğŸ¤³ å‰é¢';
            if (lower.includes('back') || lower.includes('rear')) return 'ğŸ“· èƒŒé¢åºƒè§’';

            return label; // ãƒãƒƒãƒã—ãªã„å ´åˆã¯å…ƒã®ãƒ©ãƒ™ãƒ«ã‚’è¿”ã™
        }

        // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºæ›´æ–°
        function updateStatus(text, state) {
            const indicator = state === 'connected' ? 'connected' :
                              state === 'connecting' ? 'connecting' : 'disconnected';
            statusDiv.innerHTML = `<span class="status-indicator ${indicator}"></span>${text}`;
        }

        // ãƒˆãƒ¼ã‚¹ãƒˆé€šçŸ¥
        function showToast(message, type = 'info', duration = 3000) {
            const toast = document.getElementById('toast');
            toast.textContent = message;
            toast.className = 'toast ' + type + ' show';
            setTimeout(() => { toast.classList.remove('show'); }, duration);
        }

        // ã‚«ãƒ¡ãƒ©ä¸€è¦§å–å¾—
        async function getCameras() {
            try {
                // æ¨©é™ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                const devices = await navigator.mediaDevices.enumerateDevices();
                const videoDevices = devices.filter(device => device.kind === 'videoinput');

                cameraSelect.innerHTML = '<option value="">ã‚«ãƒ¡ãƒ©ã‚’é¸æŠ...</option>';
                videoDevices.forEach(device => {
                    const option = document.createElement('option');
                    option.value = device.deviceId;
                    // ãƒ‡ãƒãƒƒã‚°ç”¨: å…ƒã®ãƒ©ãƒ™ãƒ«ã‚‚è¡¨ç¤º
                    const formatted = formatCameraLabel(device.label);
                    if (formatted && formatted !== device.label) {
                        option.text = `${formatted} (${device.label})`;
                    } else {
                        option.text = device.label || `ã‚«ãƒ¡ãƒ© ${cameraSelect.length}`;
                    }
                    cameraSelect.appendChild(option);
                });

                // èƒŒé¢ã‚«ãƒ¡ãƒ©ï¼ˆåºƒè§’ï¼‰ã‚’å„ªå…ˆçš„ã«é¸æŠ
                const backCamera = videoDevices.find(d => d.label.toLowerCase().includes('back') || d.label.toLowerCase().includes('èƒŒé¢'));
                if (backCamera) {
                    cameraSelect.value = backCamera.deviceId;
                }

                // åˆæœŸåŒ–æ™‚ã«ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•
                await startCamera(cameraSelect.value);

            } catch (err) {
                console.error('Error getting cameras:', err);
                updateStatus('ã‚«ãƒ¡ãƒ©æ¨©é™ã‚¨ãƒ©ãƒ¼', 'disconnected');
                showToast('ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã—ã¦ãã ã•ã„', 'error');
            }
        }

        // ã‚«ãƒ¡ãƒ©åˆ‡ã‚Šæ›¿ãˆã‚¤ãƒ™ãƒ³ãƒˆ
        cameraSelect.onchange = async () => {
            await startCamera(cameraSelect.value);
        };

        // ã‚«ãƒ¡ãƒ©èµ·å‹•
        async function startCamera(deviceId) {
            if (stream) {
                stream.getTracks().forEach(t => t.stop());
            }

            const constraints = {
                video: {
                    deviceId: deviceId ? { exact: deviceId } : undefined,
                    facingMode: deviceId ? undefined : 'environment', // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯èƒŒé¢
                    // width/heightã‚’æŒ‡å®šã—ãªã„ã“ã¨ã§ã€ã‚«ãƒ¡ãƒ©ã®ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ï¼ˆ4:3ãªã©ï¼‰ã‚’ä½¿ç”¨
                    advanced: [{ torch: false }] // åˆæœŸåŒ–æ™‚ã«æ˜ç¤ºçš„ã«OFF
                },
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    sampleRate: 24000 // Realtime API æ¨å¥¨
                }
            };

            try {
                stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                track = stream.getVideoTracks()[0];

                // ãƒ•ãƒ©ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã®ç¢ºèª
                const capabilities = track.getCapabilities();
                console.log("Camera Capabilities:", capabilities);

                // torch ã¾ãŸã¯ fillLightMode ã‚’ãƒã‚§ãƒƒã‚¯
                if (capabilities.torch || capabilities.fillLightMode) {
                    flashBtn.disabled = false;
                    updateStatus('ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ä½¿ç”¨å¯èƒ½', 'disconnected');
                } else {
                    flashBtn.disabled = true;
                    updateStatus('ãƒ•ãƒ©ãƒƒã‚·ãƒ¥éå¯¾å¿œ', 'disconnected');
                }

                return stream;
            } catch (err) {
                console.error('Error starting camera:', err);
                updateStatus('ã‚«ãƒ¡ãƒ©èµ·å‹•ã‚¨ãƒ©ãƒ¼', 'disconnected');
                showToast('ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã§ãã¾ã›ã‚“ã§ã—ãŸ', 'error');
                return null;
            }
        }

        // ãƒ•ãƒ©ãƒƒã‚·ãƒ¥åˆ¶å¾¡
        let isFlashOn = false;
        flashBtn.onclick = async () => {
            if (!track) return;

            isFlashOn = !isFlashOn;
            try {
                // ä¸€èˆ¬çš„ãª torch ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
                await track.applyConstraints({
                    advanced: [{ torch: isFlashOn }]
                });
                flashBtn.classList.toggle('active', isFlashOn);
            } catch (err) {
                console.error('Torch error:', err);
                // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: fillLightMode (ä¸€éƒ¨ã®Androidãªã©)
                try {
                    await track.applyConstraints({
                        advanced: [{ fillLightMode: isFlashOn ? "flash" : "off" }]
                    });
                    flashBtn.classList.toggle('active', isFlashOn);
                } catch (err2) {
                    console.error('FillLightMode error:', err2);
                    showToast('ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚’åˆ¶å¾¡ã§ãã¾ã›ã‚“ã§ã—ãŸ', 'error');
                    isFlashOn = !isFlashOn; // å¤±æ•—ã—ãŸã‚‰çŠ¶æ…‹ã‚’æˆ»ã™
                }
            }
        };

        // æ¥ç¶šå‡¦ç†
        connectBtn.onclick = async () => {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.close();
                connectBtn.textContent = 'æ¥ç¶šé–‹å§‹';
                connectBtn.classList.remove('recording');
                detectBtn.disabled = true;
                detectBtn.textContent = 'ã‚´ãƒŸæ¤œçŸ¥é–‹å§‹';
                detectBtn.classList.remove('recording');
                stopImageLoop();
                return;
            }

            // æ—¢ã«ã‚«ãƒ¡ãƒ©ãŒèµ·å‹•ã—ã¦ã„ãªã„å ´åˆã¯èµ·å‹• (å¿µã®ãŸã‚)
            if (!stream || !stream.active) {
                const deviceId = cameraSelect.value;
                await startCamera(deviceId);
            }

            if (!stream) return;

            // èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            try {
                const configRes = await fetch('/config');
                const configData = await configRes.json();
                wsToken = configData.ws_token;
            } catch (e) {
                console.error("Failed to get auth token:", e);
                updateStatus('èªè¨¼ã‚¨ãƒ©ãƒ¼', 'disconnected');
                showToast('ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“', 'error');
                return;
            }

            // WebSocketæ¥ç¶šï¼ˆå›ºå®šã®ngrokãƒ‰ãƒ¡ã‚¤ãƒ³ + role=camera + tokenï¼‰
            const wsUrl = `wss://chase-unpatient-denice.ngrok-free.dev/ws?role=camera&token=${wsToken}`;
            ws = new WebSocket(wsUrl);

            ws.onopen = async () => {
                updateStatus('æ¥ç¶šå®Œäº†', 'connected');
                showToast('ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã—ã¾ã—ãŸ', 'success');
                connectBtn.textContent = 'åˆ‡æ–­';
                connectBtn.classList.add('recording');
                detectBtn.disabled = false; // æ¤œçŸ¥ãƒœã‚¿ãƒ³æœ‰åŠ¹åŒ–

                // éŸ³å£°å‡¦ç†é–‹å§‹
                await startAudioProcessing(stream);
            };

            ws.onmessage = async (event) => {
                const data = JSON.parse(event.data);
                if (data.type === 'response.audio.delta') {
                    playAudio(data.delta);
                }
            };

            ws.onclose = () => {
                updateStatus('åˆ‡æ–­ã•ã‚Œã¾ã—ãŸ', 'disconnected');
                connectBtn.textContent = 'æ¥ç¶šé–‹å§‹';
                connectBtn.classList.remove('recording');
                detectBtn.disabled = true;
                detectBtn.textContent = 'ã‚´ãƒŸæ¤œçŸ¥é–‹å§‹';
                detectBtn.classList.remove('recording');
                stopImageLoop();
                stopAudioProcessing();
            };
        };

        // ã‚´ãƒŸæ¤œçŸ¥é–‹å§‹å‡¦ç†
        detectBtn.onclick = async () => {
            detectBtn.disabled = true; // äºŒåº¦æŠ¼ã—é˜²æ­¢

            // è¨­å®šå–å¾—
            let delay = 5;
            let interval = 3;
            try {
                const res = await fetch('/config');
                const config = await res.json();
                delay = config.detection_delay;
                interval = config.image_interval;
            } catch (e) {
                console.error("Config fetch error:", e);
            }

            // ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³
            for (let i = delay; i > 0; i--) {
                detectBtn.textContent = `é–‹å§‹ã¾ã§ ${i}ç§’...`;
                await new Promise(r => setTimeout(r, 1000));
            }

            detectBtn.textContent = 'æ¤œçŸ¥ä¸­...';
            detectBtn.classList.add('recording');

            // ç”»åƒé€ä¿¡ãƒ«ãƒ¼ãƒ—é–‹å§‹
            startImageLoop(ws, interval * 1000);
        };

        function sendTextMessage(text) {
            if (!ws || ws.readyState !== WebSocket.OPEN) return;
            const event = {
                type: "conversation.item.create",
                item: {
                    type: "message",
                    role: "user",
                    content: [{ type: "input_text", text: text }]
                }
            };
            ws.send(JSON.stringify(event));
            ws.send(JSON.stringify({ type: "response.create" }));
        }

        // ç”»åƒé€ä¿¡ãƒ«ãƒ¼ãƒ—
        async function startImageLoop(socket, intervalMs) {
            if (!intervalMs || intervalMs < 1000) intervalMs = 3000;
            console.log("Image loop started with interval:", intervalMs);
            // åˆå›å³æ™‚å®Ÿè¡Œ
            sendImage();

            // å®šæœŸå®Ÿè¡Œ
            imageInterval = setInterval(() => {
                if (socket && socket.readyState === WebSocket.OPEN) {
                    sendImage();
                } else {
                    stopImageLoop();
                }
            }, intervalMs);
        }

        function stopImageLoop() {
            if (imageInterval) {
                clearInterval(imageInterval);
                imageInterval = null;
                console.log("Image loop stopped");
            }
        }

        function sendImage() {
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0);

            // JPEG Base64å¤‰æ›
            const base64 = canvas.toDataURL('image/jpeg', 0.7).split(',')[1];

            const event = {
                type: "conversation.item.create",
                item: {
                    type: "message",
                    role: "user",
                    content: [
                        {
                            type: "input_image",
                            image_url: `data:image/jpeg;base64,${base64}`
                        }
                    ]
                }
            };
            ws.send(JSON.stringify(event));

            // ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¦æ±‚
            ws.send(JSON.stringify({ type: "response.create" }));
            console.log("Image sent");
        }

        // éŸ³å£°å‡¦ç† (AudioWorklet)
        async function startAudioProcessing(stream) {
            audioContext = new AudioContext({ sampleRate: 24000 });
            await audioContext.audioWorklet.addModule(URL.createObjectURL(new Blob([`
                class AudioProcessor extends AudioWorkletProcessor {
                    process(inputs, outputs, parameters) {
                        const input = inputs[0];
                        if (input.length > 0) {
                            const float32Data = input[0];
                            const int16Data = new Int16Array(float32Data.length);
                            for (let i = 0; i < float32Data.length; i++) {
                                const s = Math.max(-1, Math.min(1, float32Data[i]));
                                int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                            }
                            this.port.postMessage(int16Data.buffer);
                        }
                        return true;
                    }
                }
                registerProcessor('audio-processor', AudioProcessor);
            `], { type: 'application/javascript' })));

            const source = audioContext.createMediaStreamSource(stream);
            audioWorkletNode = new AudioWorkletNode(audioContext, 'audio-processor');

            audioWorkletNode.port.onmessage = (event) => {
                if (ws && ws.readyState === WebSocket.OPEN) {
                    // Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦é€ä¿¡
                    const base64Audio = arrayBufferToBase64(event.data);
                    ws.send(JSON.stringify({
                        type: "input_audio_buffer.append",
                        audio: base64Audio
                    }));
                }
            };

            source.connect(audioWorkletNode);
            audioWorkletNode.connect(audioContext.destination); // ãƒ¢ãƒ‹ã‚¿ãƒ¼ç”¨ï¼ˆå¿…è¦ãªã‘ã‚Œã°å‰Šé™¤ï¼‰
        }

        function stopAudioProcessing() {
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
        }

        // éŸ³å£°å†ç”Ÿ
        let nextStartTime = 0;
        function playAudio(base64Delta) {
            if (!audioContext) return;

            const binaryString = window.atob(base64Delta);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            const int16Data = new Int16Array(bytes.buffer);
            const float32Data = new Float32Array(int16Data.length);
            for (let i = 0; i < int16Data.length; i++) {
                float32Data[i] = int16Data[i] / 32768.0;
            }

            const buffer = audioContext.createBuffer(1, float32Data.length, 24000);
            buffer.getChannelData(0).set(float32Data);

            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.connect(audioContext.destination);

            if (nextStartTime < audioContext.currentTime) {
                nextStartTime = audioContext.currentTime;
            }
            source.start(nextStartTime);
            nextStartTime += buffer.duration;
        }

        function arrayBufferToBase64(buffer) {
            let binary = '';
            const bytes = new Uint8Array(buffer);
            const len = bytes.byteLength;
            for (let i = 0; i < len; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return window.btoa(binary);
        }

        // åˆæœŸåŒ–
        getCameras();
    </script>
</body>

</html>
